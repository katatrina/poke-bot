server:
  port: 8080

qdrant:
  host: "localhost"
  port: 6334
  collection: "pokemons"

ollama:
  base_url: "http://localhost:11434"
  chat_model: "qwen2.5-coder:3b"
  embedding_model: "nomic-embed-text"

rag:
  chunk_size: 600
  chunk_overlap: 100
  top_k: 5
  temperature: 0.3
  max_conversation_turns: 15    # Max 15 turns (30 messages) before forcing new chat
  max_total_tokens: 2500        # Max 2500 tokens total (using tiktoken)
  max_history_turns: 5          # Send only last 5 turns (10 messages) to LLM for context
  max_context_tokens: 4000      # Max tokens for full prompt (RAG + history + system prompt)
